{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Glaucoma-Detection.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ajju7669/crime_data_analysis/blob/master/Glaucoma_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhnhxadWWAgy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "44e77b47-b877-45da-c770-67267435490e"
      },
      "source": [
        "!clone github https://github.com/kesaroid/Glaucoma-Detection.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: clone: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IZU6m9OWGmP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "a350bea8-a49e-4c90-e36b-c44ff842e81b"
      },
      "source": [
        "!git clone https://github.com/kesaroid/Glaucoma-Detection.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Glaucoma-Detection'...\n",
            "remote: Enumerating objects: 1008, done.\u001b[K\n",
            "remote: Total 1008 (delta 0), reused 0 (delta 0), pack-reused 1008\u001b[K\n",
            "Receiving objects: 100% (1008/1008), 47.97 MiB | 44.77 MiB/s, done.\n",
            "Resolving deltas: 100% (149/149), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_syaoGyVWPF4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd Glaucoma-Detection"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flsYZQ26Z-qv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "13571506-0146-4e8d-c763-50ca75dca4fa"
      },
      "source": [
        "!cat CNN.py"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cat: CNN.py: No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxAm9ZOAaCDv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "746e9446-e030-45fb-e5a0-b48459aeabd6"
      },
      "source": [
        "!pycat CNN.py"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: pycat: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-YVOyzsaS6u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "4af86f50-01ef-4313-fcbc-06eea76486b2"
      },
      "source": [
        "CNN.py"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-4367a38bb659>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mCNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'CNN' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwWrI97padMD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "965ed963-4626-4c5f-c150-7bda126b35e8"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/G\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WZAfEdqar8J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ae715887-639e-44a3-fc96-532dd867cb9a"
      },
      "source": [
        "!cat CNN.py"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "from keras.preprocessing.image import ImageDataGenerator\n",
            "from keras.models import Model\n",
            "from keras.layers import Input, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
            "from keras.layers import BatchNormalization, Activation, Dropout, Flatten, Dense\n",
            "from keras import backend as K\n",
            "from keras import optimizers\n",
            "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
            "from imgaug import augmenters as iaa\n",
            "\n",
            "img_width, img_height = 256, 256\n",
            "input_shape = (img_width, img_height, 3)\n",
            "\n",
            "train_data_dir = \"data/train\"\n",
            "validation_data_dir = \"data/validation\"\n",
            "nb_train_samples = <training samples>\n",
            "nb_validation_samples = <validation samples>\n",
            "batch_size = 16\n",
            "epochs = 100\n",
            "\n",
            "input = Input(shape=input_shape)\n",
            "\n",
            "block1 = BatchNormalization(name='norm_0')(input)\n",
            "\n",
            "# Block 1\n",
            "block1 = Conv2D(8, (3,3), name='conv_11', activation='relu')(block1)\n",
            "block1 = Conv2D(16, (3,3), name='conv_12', activation='relu')(block1)\n",
            "block1 = Conv2D(32, (3,3), name='conv_13', activation='relu')(block1)\n",
            "block1 = Conv2D(64, (3,3), name='conv_14', activation='relu')(block1)\n",
            "block1 = MaxPooling2D(pool_size=(2, 2))(block1)\n",
            "block1 = BatchNormalization(name='norm_1')(block1)\n",
            "\n",
            "block1 = Conv2D(16, 1)(block1)\n",
            "\n",
            "# Block 2\n",
            "block2 = Conv2D(32, (3,3), name='conv_21', activation='relu')(block1)\n",
            "block2 = Conv2D(64, (3,3), name='conv_22', activation='relu')(block2)\n",
            "block2 = Conv2D(64, (3,3), name='conv_23', activation='relu')(block2)\n",
            "block2 = Conv2D(128, (3,3), name='conv_24', activation='relu')(block2)\n",
            "block2 = MaxPooling2D(pool_size=(2, 2))(block2)\n",
            "block2 = BatchNormalization(name='norm_2')(block2)\n",
            "\n",
            "block2 = Conv2D(64, 1)(block2)\n",
            "\n",
            "# Block 3\n",
            "block3 = Conv2D(64, (3,3), name='conv_31', activation='relu')(block2)\n",
            "block3 = Conv2D(128, (3,3), name='conv_32', activation='relu')(block3)\n",
            "block3 = Conv2D(128, (3,3), name='conv_33', activation='relu')(block3)\n",
            "block3 = Conv2D(64, (3,3), name='conv_34', activation='relu')(block3)\n",
            "block3 = MaxPooling2D(pool_size=(2, 2))(block3)\n",
            "block3 = BatchNormalization(name='norm_3')(block3)\n",
            "\n",
            "# Block 4\n",
            "block4 = Conv2D(64, (3,3), name='conv_41', activation='relu')(block3)\n",
            "block4 = Conv2D(32, (3,3), name='conv_42', activation='relu')(block4)\n",
            "block4 = Conv2D(16, (3,3), name='conv_43', activation='relu')(block4)\n",
            "block4 = Conv2D(8, (2,2), name='conv_44', activation='relu')(block4)\n",
            "block4 = MaxPooling2D(pool_size=(2, 2))(block4)\n",
            "block4 = BatchNormalization(name='norm_4')(block4)\n",
            "\n",
            "block4 = Conv2D(2, 1)(block4)\n",
            "\n",
            "block5 = GlobalAveragePooling2D()(block4)\n",
            "output = Activation('softmax')(block5)\n",
            "\n",
            "model = Model(inputs=[input], outputs=[output])\n",
            "model.summary()\n",
            "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False), metrics=[\"accuracy\"])\n",
            "\n",
            "# Initiate the train and test generators with data Augumentation\n",
            "sometimes = lambda aug: iaa.Sometimes(0.6, aug)\n",
            "seq = iaa.Sequential([\n",
            "                      iaa.GaussianBlur(sigma=(0 , 1.0)),\n",
            "                      iaa.Sharpen(alpha=1, lightness=0),\n",
            "                      iaa.CoarseDropout(p=0.1, size_percent=0.15),\n",
            "                              sometimes(iaa.Affine(\n",
            "                                                    scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
            "                                                    translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
            "                                                    rotate=(-30, 30),\n",
            "                                                    shear=(-16, 16)))\n",
            "                    ])\n",
            "\n",
            "\n",
            "train_datagen = ImageDataGenerator(\n",
            "    rescale=1./255,\n",
            "    preprocessing_function=seq.augment_image,\n",
            "    horizontal_flip=True,\n",
            "    vertical_flip=True)\n",
            "\n",
            "test_datagen = ImageDataGenerator(\n",
            "    rescale=1./255,\n",
            "    horizontal_flip=True,\n",
            "    vertical_flip=True)\n",
            "\n",
            "train_generator = train_datagen.flow_from_directory(\n",
            "    train_data_dir,\n",
            "    target_size=(img_height, img_width),\n",
            "    batch_size=batch_size,\n",
            "    class_mode=\"categorical\")\n",
            "\n",
            "validation_generator = test_datagen.flow_from_directory(\n",
            "    validation_data_dir,\n",
            "    target_size=(img_height, img_width),\n",
            "    class_mode=\"categorical\")\n",
            "\n",
            "checkpoint = ModelCheckpoint(\"f1.h5\", monitor='acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
            "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=2, verbose=0, mode='auto', cooldown=0, min_lr=0)\n",
            "\n",
            "model.fit_generator(\n",
            "    train_generator,\n",
            "    steps_per_epoch=nb_train_samples // batch_size,\n",
            "    epochs=epochs,\n",
            "    validation_data=validation_generator,\n",
            "    validation_steps=nb_validation_samples // batch_size,\n",
            "    callbacks=[checkpoint, reduce_lr]\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tO1Kex97sg-l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "c1f7dd09-df9e-4aa4-c186-3605e5b36591"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.layers import BatchNormalization, Activation, Dropout, Flatten, Dense\n",
        "from keras import backend as K\n",
        "from keras import optimizers\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from imgaug import augmenters as iaa\n",
        "\n",
        "img_width, img_height = 256, 256\n",
        "input_shape = (img_width, img_height, 3)\n",
        "\n",
        "train_data_dir = \"data/train\"\n",
        "validation_data_dir = \"data/validation\"\n",
        "nb_train_samples =100\n",
        "nb_validation_samples = 100\n",
        "batch_size = 16\n",
        "epochs = 100\n",
        "\n",
        "input = Input(shape=input_shape)\n",
        "\n",
        "block1 = BatchNormalization(name='norm_0')(input)\n",
        "\n",
        "# Block 1\n",
        "block1 = Conv2D(8, (3,3), name='conv_11', activation='relu')(block1)\n",
        "block1 = Conv2D(16, (3,3), name='conv_12', activation='relu')(block1)\n",
        "block1 = Conv2D(32, (3,3), name='conv_13', activation='relu')(block1)\n",
        "block1 = Conv2D(64, (3,3), name='conv_14', activation='relu')(block1)\n",
        "block1 = MaxPooling2D(pool_size=(2, 2))(block1)\n",
        "block1 = BatchNormalization(name='norm_1')(block1)\n",
        "\n",
        "block1 = Conv2D(16, 1)(block1)\n",
        "\n",
        "# Block 2\n",
        "block2 = Conv2D(32, (3,3), name='conv_21', activation='relu')(block1)\n",
        "block2 = Conv2D(64, (3,3), name='conv_22', activation='relu')(block2)\n",
        "block2 = Conv2D(64, (3,3), name='conv_23', activation='relu')(block2)\n",
        "block2 = Conv2D(128, (3,3), name='conv_24', activation='relu')(block2)\n",
        "block2 = MaxPooling2D(pool_size=(2, 2))(block2)\n",
        "block2 = BatchNormalization(name='norm_2')(block2)\n",
        "\n",
        "block2 = Conv2D(64, 1)(block2)\n",
        "\n",
        "# Block 3\n",
        "block3 = Conv2D(64, (3,3), name='conv_31', activation='relu')(block2)\n",
        "block3 = Conv2D(128, (3,3), name='conv_32', activation='relu')(block3)\n",
        "block3 = Conv2D(128, (3,3), name='conv_33', activation='relu')(block3)\n",
        "block3 = Conv2D(64, (3,3), name='conv_34', activation='relu')(block3)\n",
        "block3 = MaxPooling2D(pool_size=(2, 2))(block3)\n",
        "block3 = BatchNormalization(name='norm_3')(block3)\n",
        "\n",
        "# Block 4\n",
        "block4 = Conv2D(64, (3,3), name='conv_41', activation='relu')(block3)\n",
        "block4 = Conv2D(32, (3,3), name='conv_42', activation='relu')(block4)\n",
        "block4 = Conv2D(16, (3,3), name='conv_43', activation='relu')(block4)\n",
        "block4 = Conv2D(8, (2,2), name='conv_44', activation='relu')(block4)\n",
        "block4 = MaxPooling2D(pool_size=(2, 2))(block4)\n",
        "block4 = BatchNormalization(name='norm_4')(block4)\n",
        "\n",
        "block4 = Conv2D(2, 1)(block4)\n",
        "\n",
        "block5 = GlobalAveragePooling2D()(block4)\n",
        "output = Activation('softmax')(block5)\n",
        "\n",
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.summary()\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False), metrics=[\"accuracy\"])\n",
        "\n",
        "# Initiate the train and test generators with data Augumentation\n",
        "sometimes = lambda aug: iaa.Sometimes(0.6, aug)\n",
        "seq = iaa.Sequential([\n",
        "                      iaa.GaussianBlur(sigma=(0 , 1.0)),\n",
        "                      iaa.Sharpen(alpha=1, lightness=0),\n",
        "                      iaa.CoarseDropout(p=0.1, size_percent=0.15),\n",
        "                              sometimes(iaa.Affine(\n",
        "                                                    scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
        "                                                    translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
        "                                                    rotate=(-30, 30),\n",
        "                                                    shear=(-16, 16)))\n",
        "                    ])\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    preprocessing_function=seq.augment_image,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\")\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    class_mode=\"categorical\")\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"f1.h5\", monitor='acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=2, verbose=0, mode='auto', cooldown=0, min_lr=0)\n",
        "\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=nb_validation_samples // batch_size,\n",
        "    callbacks=[checkpoint, reduce_lr]\n",
        ")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-52a9b3548946>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_validation_samples\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_lr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1656\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1658\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    235\u001b[0m                             \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m                             workers=0)\n\u001b[0m\u001b[1;32m    238\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                         \u001b[0;31m# No need for try/except because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(self, generator, steps, callbacks, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   1715\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1716\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1717\u001b[0;31m             verbose=verbose)\n\u001b[0m\u001b[1;32m   1718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1719\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(model, generator, steps, callbacks, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msteps_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m             \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mouts_per_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtest_on_batch\u001b[0;34m(self, x, y, sample_weight)\u001b[0m\n\u001b[1;32m   1486\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1487\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1488\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1489\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjJYD750y3j8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "60af78dd-3d6a-40da-b10e-e79febd07ad8"
      },
      "source": [
        "!cat GUI.py"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "from tkinter import *\n",
            "from tkinter import messagebox\n",
            "from keras.models import load_model\n",
            "import matplotlib.pyplot as plt\n",
            "import cv2\n",
            "import numpy as np\n",
            "import os\n",
            "import pandas\n",
            "\n",
            "\n",
            "model = load_model('f1.h5')\n",
            "\n",
            "\n",
            "def get_filenames():\n",
            "    global path\n",
            "    path = r\"test\"\n",
            "    return os.listdir(path)\n",
            "\n",
            "\n",
            "def curselect(event):\n",
            "    global spath\n",
            "    index = t1.curselection()[0]\n",
            "    spath = t1.get(index)\n",
            "    return(spath)\n",
            "\n",
            "\n",
            "def autoroi(img):\n",
            "\n",
            "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
            "\n",
            "    thresh = cv2.threshold(gray_img, 130, 255, cv2.THRESH_BINARY)[1]\n",
            "    thresh = cv2.dilate(thresh, None, iterations=5)\n",
            "\n",
            "    contours, hierarchy = cv2.findContours(\n",
            "        thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
            "\n",
            "    biggest = max(contours, key=cv2.contourArea)\n",
            "    x, y, w, h = cv2.boundingRect(biggest)\n",
            "    cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
            "    roi = img[y:y+h, x:x+w]\n",
            "\n",
            "    return roi\n",
            "\n",
            "\n",
            "def prediction():\n",
            "\n",
            "    img = cv2.imread('test/%s' % (spath))\n",
            "    img = autoroi(img)\n",
            "    img = cv2.resize(img, (256, 256))\n",
            "    img = np.reshape(img, [1, 256, 256, 3])\n",
            "\n",
            "    prob = model.predict(img)\n",
            "    Class = prob.argmax(axis=-1)\n",
            "\n",
            "    return(Class)\n",
            "\n",
            "\n",
            "def run():\n",
            "\n",
            "    Class = prediction()\n",
            "    if (Class == 0):\n",
            "        messagebox.showinfo('Prediction', 'You have been diagnosed with Glaucoma')\n",
            "    else:\n",
            "        messagebox.showinfo('Prediction', 'Congratulations! You are Healthy')\n",
            "\n",
            "\n",
            "def run_all():\n",
            "\n",
            "    x = os.listdir(path)\n",
            "    y = []\n",
            "    affected = 0\n",
            "\n",
            "    for i in x:\n",
            "        img = cv2.imread('test/%s' % (i))\n",
            "        img = autoroi(img)\n",
            "        img = cv2.resize(img, (256, 256))\n",
            "        img = np.reshape(img, [1, 256, 256, 3])\n",
            "\n",
            "        prob = model.predict(img)\n",
            "        Class = prob.argmax(axis=-1)\n",
            "        y.append(Class[0])\n",
            "        if Class == 1:\n",
            "            affected += 1\n",
            "\n",
            "    df = pandas.DataFrame(data=y, index=x, columns=[\"output\"])\n",
            "    df.to_csv('output.csv', sep=',')\n",
            "\n",
            "\n",
            "def ROI():\n",
            "    img = cv2.imread('test/%s' % (spath))\n",
            "    roi = autoroi(img)\n",
            "    cv2.imshow(\"Region of Interest\", roi)\n",
            "\n",
            "\n",
            "def preview():\n",
            "    img = cv2.imread('test/%s' % (spath))\n",
            "    cv2.imshow('Image', img)\n",
            "\n",
            "\n",
            "def graph():\n",
            "\n",
            "    total = len(os.listdir(path))\n",
            "    affected = pandas.read_csv('output.csv')\n",
            "    affected = affected['output'].sum()\n",
            "\n",
            "    healthy = total - affected\n",
            "\n",
            "    piey = [\"Glaucomatous\", \"Healthy\"]\n",
            "    piex = [affected, healthy]\n",
            "\n",
            "    plt.axis(\"equal\")\n",
            "    plt.pie(piex, labels=piey, radius=1.5, autopct='%0.1f%%', explode=[0.2, 0])\n",
            "    plt.show()\n",
            "\n",
            "# Frontend GUI\n",
            "\n",
            "\n",
            "window = Tk()\n",
            "window.title(\"Glaucoma Detection\")\n",
            "window.geometry('1000x550')\n",
            "window.configure(background='grey')\n",
            "\n",
            "l1 = Label(window, text=\"Test Image\", font=(\"Arial\", 20), padx=10, bg='grey')\n",
            "l1.grid(row=0, column=0)\n",
            "\n",
            "b1 = Button(window, text='Run', font=(\"Arial\", 20), command=run)\n",
            "b1.grid(row=1, column=3)\n",
            "\n",
            "b2 = Button(window, text='Preview', font=(\"Arial\", 20), command=preview)\n",
            "b2.grid(row=1, column=2, rowspan=2, padx=10)\n",
            "\n",
            "b2 = Button(window, text='ROI', font=(\"Arial\", 20), command=ROI)\n",
            "b2.grid(row=2, column=2, rowspan=3, padx=10)\n",
            "\n",
            "b3 = Button(window, text='Run all', font=(\"Arial\", 20), command=run_all)\n",
            "b3.grid(row=2, column=3)\n",
            "\n",
            "b4 = Button(window, text='Graph', font=(\"Arial\", 20), command=graph)\n",
            "b4.grid(row=3, column=3)\n",
            "\n",
            "t1 = Listbox(window, height=20, width=60, selectmode=SINGLE, font=(\"Arial\", 15), justify=CENTER)\n",
            "t1.grid(row=1, column=0, rowspan=3, padx=10)\n",
            "for filename in get_filenames():\n",
            "    t1.insert(END, filename)\n",
            "t1.bind('<<ListboxSelect>>', curselect)\n",
            "\n",
            "sb1 = Scrollbar(window)\n",
            "sb1.grid(row=1, column=1, rowspan=4)\n",
            "\n",
            "t1.configure(yscrollcommand=sb1.set)\n",
            "sb1.configure(command=t1.yview)\n",
            "\n",
            "\n",
            "window.mainloop()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUFRWPe6y6TA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "4c77a7e5-a985-4fdc-b29c-405e1e5733b9"
      },
      "source": [
        "from tkinter import *\n",
        "from tkinter import messagebox\n",
        "from keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas\n",
        "\n",
        "\n",
        "model = load_model('f1.h5')\n",
        "\n",
        "\n",
        "def get_filenames():\n",
        "    global path\n",
        "    path = r\"test\"\n",
        "    return os.listdir(path)\n",
        "\n",
        "\n",
        "def curselect(event):\n",
        "    global spath\n",
        "    index = t1.curselection()[0]\n",
        "    spath = t1.get(index)\n",
        "    return(spath)\n",
        "\n",
        "\n",
        "def autoroi(img):\n",
        "\n",
        "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    thresh = cv2.threshold(gray_img, 130, 255, cv2.THRESH_BINARY)[1]\n",
        "    thresh = cv2.dilate(thresh, None, iterations=5)\n",
        "\n",
        "    contours, hierarchy = cv2.findContours(\n",
        "        thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    biggest = max(contours, key=cv2.contourArea)\n",
        "    x, y, w, h = cv2.boundingRect(biggest)\n",
        "    cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "    roi = img[y:y+h, x:x+w]\n",
        "\n",
        "    return roi\n",
        "\n",
        "\n",
        "def prediction():\n",
        "\n",
        "    img = cv2.imread('test/%s' % (spath))\n",
        "    img = autoroi(img)\n",
        "    img = cv2.resize(img, (256, 256))\n",
        "    img = np.reshape(img, [1, 256, 256, 3])\n",
        "\n",
        "    prob = model.predict(img)\n",
        "    Class = prob.argmax(axis=-1)\n",
        "\n",
        "    return(Class)\n",
        "\n",
        "\n",
        "def run():\n",
        "\n",
        "    Class = prediction()\n",
        "    if (Class == 0):\n",
        "        messagebox.showinfo('Prediction', 'You have been diagnosed with Glaucoma')\n",
        "    else:\n",
        "        messagebox.showinfo('Prediction', 'Congratulations! You are Healthy')\n",
        "\n",
        "\n",
        "def run_all():\n",
        "\n",
        "    x = os.listdir(path)\n",
        "    y = []\n",
        "    affected = 0\n",
        "\n",
        "    for i in x:\n",
        "        img = cv2.imread('test/%s' % (i))\n",
        "        img = autoroi(img)\n",
        "        img = cv2.resize(img, (256, 256))\n",
        "        img = np.reshape(img, [1, 256, 256, 3])\n",
        "\n",
        "        prob = model.predict(img)\n",
        "        Class = prob.argmax(axis=-1)\n",
        "        y.append(Class[0])\n",
        "        if Class == 1:\n",
        "            affected += 1\n",
        "\n",
        "    df = pandas.DataFrame(data=y, index=x, columns=[\"output\"])\n",
        "    df.to_csv('output.csv', sep=',')\n",
        "\n",
        "\n",
        "def ROI():\n",
        "    img = cv2.imread('test/%s' % (spath))\n",
        "    roi = autoroi(img)\n",
        "    cv2.imshow(\"Region of Interest\", roi)\n",
        "\n",
        "\n",
        "def preview():\n",
        "    img = cv2.imread('test/%s' % (spath))\n",
        "    cv2.imshow('Image', img)\n",
        "\n",
        "\n",
        "def graph():\n",
        "\n",
        "    total = len(os.listdir(path))\n",
        "    affected = pandas.read_csv('output.csv')\n",
        "    affected = affected['output'].sum()\n",
        "\n",
        "    healthy = total - affected\n",
        "\n",
        "    piey = [\"Glaucomatous\", \"Healthy\"]\n",
        "    piex = [affected, healthy]\n",
        "\n",
        "    plt.axis(\"equal\")\n",
        "    plt.pie(piex, labels=piey, radius=1.5, autopct='%0.1f%%', explode=[0.2, 0])\n",
        "    plt.show()\n",
        "\n",
        "# Frontend GUI\n",
        "\n",
        "\n",
        "window = Tk()\n",
        "window.title(\"Glaucoma Detection\")\n",
        "window.geometry('1000x550')\n",
        "window.configure(background='grey')\n",
        "\n",
        "l1 = Label(window, text=\"Test Image\", font=(\"Arial\", 20), padx=10, bg='grey')\n",
        "l1.grid(row=0, column=0)\n",
        "\n",
        "b1 = Button(window, text='Run', font=(\"Arial\", 20), command=run)\n",
        "b1.grid(row=1, column=3)\n",
        "\n",
        "b2 = Button(window, text='Preview', font=(\"Arial\", 20), command=preview)\n",
        "b2.grid(row=1, column=2, rowspan=2, padx=10)\n",
        "\n",
        "b2 = Button(window, text='ROI', font=(\"Arial\", 20), command=ROI)\n",
        "b2.grid(row=2, column=2, rowspan=3, padx=10)\n",
        "\n",
        "b3 = Button(window, text='Run all', font=(\"Arial\", 20), command=run_all)\n",
        "b3.grid(row=2, column=3)\n",
        "\n",
        "b4 = Button(window, text='Graph', font=(\"Arial\", 20), command=graph)\n",
        "b4.grid(row=3, column=3)\n",
        "\n",
        "t1 = Listbox(window, height=20, width=60, selectmode=SINGLE, font=(\"Arial\", 15), justify=CENTER)\n",
        "t1.grid(row=1, column=0, rowspan=3, padx=10)\n",
        "for filename in get_filenames():\n",
        "    t1.insert(END, filename)\n",
        "t1.bind('<<ListboxSelect>>', curselect)\n",
        "\n",
        "sb1 = Scrollbar(window)\n",
        "sb1.grid(row=1, column=1, rowspan=4)\n",
        "\n",
        "t1.configure(yscrollcommand=sb1.set)\n",
        "sb1.configure(command=t1.yview)\n",
        "\n",
        "\n",
        "window.mainloop()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TclError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTclError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-88bcaadb7540>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m \u001b[0mwindow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Glaucoma Detection\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeometry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1000x550'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/tkinter/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, screenName, baseName, className, useTk, sync, use)\u001b[0m\n\u001b[1;32m   2021\u001b[0m                 \u001b[0mbaseName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseName\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2022\u001b[0m         \u001b[0minteractive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2023\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tkinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreenName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteractive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwantobjects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2024\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2025\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loadtk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTclError\u001b[0m: no display name and no $DISPLAY environment variable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cG5ooN2k1UYx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}